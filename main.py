import os
import json
import time
import random
import difflib
import requests
from datetime import datetime
from bs4 import BeautifulSoup

# [í•µì‹¬] ê¹ƒí—ˆë¸Œ ì„œë²„ì—ì„œë„ í¬ë¡¬ ë“œë¼ì´ë²„ë¥¼ ìë™ìœ¼ë¡œ ì¡ì•„ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By

GITHUB_USER = "rodolfochoi911-lgtm"       # ì˜ˆ: rodolfochoi911-lgtm
REPO_NAME = "competitor-monitor" # ì˜ˆ: competitor-monitor

SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL") 

DATA_DIR = "data"
REPORT_DIR = "docs/reports"
TODAY_STR = datetime.now().strftime("%Y-%m-%d")

# í´ë” ì—†ìœ¼ë©´ ìë™ ìƒì„±
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(REPORT_DIR, exist_ok=True)

def setup_driver():
    """ê¹ƒí—ˆë¸Œ ì•¡ì…˜ ì„œë²„ìš© í—¤ë“œë¦¬ìŠ¤ í¬ë¡¬ ì„¤ì • (ìë™ ì„¤ì¹˜ ì ìš©)"""
    chrome_options = Options()
    chrome_options.add_argument("--headless") 
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")
    
    # [í•µì‹¬] ë“œë¼ì´ë²„ ë§¤ë‹ˆì €ê°€ ì•Œì•„ì„œ ì„¤ì¹˜í•˜ê³  ì‹¤í–‰í•¨ (ë²„ì „ ì—ëŸ¬ í•´ê²°!)
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)
    return driver

def remove_popups(driver):
    """í™”ë©´ ê°€ë¦¬ëŠ” íŒì—… ê°•ì œ ì‚­ì œ"""
    try:
        driver.execute_script("""
            var popups = document.querySelectorAll('.popup, .modal, .layer, .dimmed, .overlay, .toast, .banner, #popup');
            popups.forEach(function(element) { element.remove(); });
        """)
    except:
        pass

def clean_html(html_source):
    """HTML ë³¸ë¬¸ë§Œ ì¶”ì¶œ (ë…¸ì´ì¦ˆ ì œê±°)"""
    soup = BeautifulSoup(html_source, 'html.parser')
    for tag in soup(['script', 'style', 'meta', 'noscript', 'header', 'footer', 'iframe', 'button', 'input', 'nav', 'aside']):
        tag.decompose()
    body = soup.find('body')
    return body.prettify() if body else "No Content"

def crawl_site_logic(driver, site_name, base_url, pagination_param=None):
    print(f"ğŸš€ [{site_name}] ë¶„ì„ ì‹œì‘...")
    collected_links = []
    last_page_links = []
    page = 1
    
    while True:
        # URL ìƒì„± (í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬)
        if pagination_param:
            connector = '&' if '?' in base_url else '?'
            target_url = f"{base_url}{connector}{pagination_param}={page}"
        else:
            target_url = base_url
            
        try:
            driver.get(target_url)
            time.sleep(2)
            remove_popups(driver)
            
            # ë§í¬ ì¶”ì¶œ (a íƒœê·¸ ì¤‘ event, view ë“±ì´ í¬í•¨ëœ ê²ƒ)
            links = driver.find_elements(By.TAG_NAME, "a")
            current_page_links = []
            
            for link in links:
                try:
                    href = link.get_attribute('href')
                    if href and ('event' in href or 'view' in href or 'detail' in href) and not href.startswith('#') and 'javascript' not in href:
                         # ìƒëŒ€ê²½ë¡œ ì²˜ë¦¬
                        if href.startswith('/'):
                            from urllib.parse import urljoin
                            href = urljoin(base_url, href)
                            
                        if href not in current_page_links:
                            current_page_links.append(href)
                except:
                    continue
            
            print(f"  - Page {page}: {len(current_page_links)}ê°œ ë°œê²¬")

            if not current_page_links: break
            if sorted(current_page_links) == sorted(last_page_links): break # ì¤‘ë³µ(ë) ì²´í¬

            for lnk in current_page_links:
                if lnk not in collected_links:
                    collected_links.append(lnk)

            if not pagination_param: break # ë‹¨ì¼ í˜ì´ì§€ëŠ” 1íšŒë§Œ
            
            last_page_links = current_page_links
            page += 1
            if page > 10: break # ì•ˆì „ì¥ì¹˜

        except Exception as e:
            print(f"  âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
            break

    # ìƒì„¸ í˜ì´ì§€ ë”¥ë‹¤ì´ë¸Œ
    print(f"  ğŸ” ìƒì„¸ í˜ì´ì§€ ìŠ¤ìº” ì¤‘ ({len(collected_links)}ê°œ)...")
    site_data = {}
    for link in collected_links: 
        try:
            driver.get(link)
            time.sleep(1)
            remove_popups(driver)
            site_data[link] = clean_html(driver.page_source)
        except:
            pass
            
    return site_data

def main():
    driver = setup_driver()
    
    competitors = [
        {"name": "SKT Shop", "url": "https://shop.tworld.co.kr/exhibition/submain", "param": None},
        {"name": "SKT Air", "url": "https://sktair-event.com/", "param": None},
        {"name": "KT M Mobile", "url": "https://www.ktmmobile.com/event/eventBoardList.do", "param": None},
        {"name": "U+ U Mobile", "url": "https://www.uplusumobile.com/event-benefit/event/ongoing", "param": None},
        {"name": "LG HelloVision", "url": "https://direct.lghellovision.net/event/viewEventList.do?returnTab=allli", "param": "pageIndex"},
        {"name": "Skylife", "url": "https://www.skylife.co.kr/event?category=mobile", "param": "page"}
    ]
    
    today_results = {}
    for comp in competitors:
        try:
            today_results[comp['name']] = crawl_site_logic(driver, comp['name'], comp['url'], comp['param'])
        except Exception as e:
            print(f"âŒ {comp['name']} ì‹¤íŒ¨: {e}")
    
    driver.quit()
    
    # ë°ì´í„° ë¹„êµ ë° ë¦¬í¬íŠ¸ ì‘ì„±
    latest_file = os.path.join(DATA_DIR, "latest_data.json")
    yesterday_results = {}
    if os.path.exists(latest_file):
        with open(latest_file, "r", encoding="utf-8") as f:
            yesterday_results = json.load(f)
            
    report_html = f"<h1>ğŸ“… {TODAY_STR} ê²½ìŸì‚¬ ë¦¬í¬íŠ¸</h1><hr>"
    has_change = False
    
    for name, pages in today_results.items():
        site_changes = ""
        old_pages = yesterday_results.get(name, {})
        all_urls = set(pages.keys()) | set(old_pages.keys())
        
        for url in all_urls:
            if url in pages and url not in old_pages:
                has_change = True
                site_changes += f"<h3 style='color:green'>[NEW] <a href='{url}'>ìƒˆ ì´ë²¤íŠ¸</a></h3><br>"
            elif url not in pages and url in old_pages:
                has_change = True
                site_changes += f"<h3 style='color:red'>[DELETED] <a href='{url}'>ì¢…ë£Œë¨</a></h3><br>"
            elif pages[url].replace(" ","") != old_pages[url].replace(" ",""):
                has_change = True
                diff = difflib.HtmlDiff().make_table(old_pages[url].splitlines(), pages[url].splitlines(), context=True, numlines=3)
                site_changes += f"<h3 style='color:orange'>[UPDATED] <a href='{url}'>ë‚´ìš© ë³€ê²½</a></h3>{diff}<br>"
        
        if site_changes:
            report_html += f"<h2>{name}</h2>{site_changes}<hr>"

    if has_change:
        filename = f"report_{TODAY_STR}.html"
        with open(os.path.join(REPORT_DIR, filename), "w", encoding="utf-8") as f:
            f.write(report_html)
        with open(latest_file, "w", encoding="utf-8") as f:
            json.dump(today_results, f, ensure_ascii=False)
            
        # ìŠ¬ë™ ì „ì†¡
        report_url = f"https://{GITHUB_USER}.github.io/{REPO_NAME}/reports/{filename}"
        payload = {"text": f"ğŸ“¢ *[{TODAY_STR}] ë³€ë™ ê°ì§€!* \në¦¬í¬íŠ¸ í™•ì¸: {report_url}"}
        
        if SLACK_WEBHOOK_URL:
            requests.post(SLACK_WEBHOOK_URL, json=payload)
            print("âœ… ìŠ¬ë™ ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ")
        else:
            print("âš ï¸ ìŠ¬ë™ URL ì—†ìŒ (Secrets ì„¤ì • í™•ì¸ í•„ìš”)")
    else:
        print("âœ… ë³€ë™ ì‚¬í•­ ì—†ìŒ")

if __name__ == "__main__":
    main()
