"""
[í”„ë¡œì íŠ¸] ê²½ìŸì‚¬ í”„ë¡œëª¨ì…˜ ëª¨ë‹ˆí„°ë§ ìë™í™” ì‹œìŠ¤í…œ
[ì‘ì„±ì] ìµœì§€ì› (GTM Strategy)
[ì—…ë°ì´íŠ¸] 2026-01-29 (íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€ + ë¬´ë£Œ í•œë„ ìµœì í™”)
"""

import os
import json
import time
import glob
from datetime import datetime
import difflib
import requests
from bs4 import BeautifulSoup

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# =========================================================
# [ì„¤ì •]
# =========================================================
GITHUB_USER = "rodolfochoi911-lgtm" 
REPO_NAME = "competitor-monitor" 
SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL") 

DATA_DIR = "data"
DOCS_DIR = "docs"
REPORT_DIR = "docs/reports"

# [ìˆ˜ì •ë¨] ë‚ ì§œë¿ë§Œ ì•„ë‹ˆë¼ ì‹œê°„ê¹Œì§€ ì •í™•í•˜ê²Œ ê¸°ë¡
NOW = datetime.now()
TODAY_STR = NOW.strftime("%Y-%m-%d")
TIME_STR = NOW.strftime("%H:%M:%S") # ì˜ˆ: 14:30:05

os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(REPORT_DIR, exist_ok=True)

def setup_driver():
    chrome_options = Options()
    chrome_options.add_argument("--headless") 
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")
    
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)
    return driver

def remove_popups(driver):
    try:
        driver.execute_script("""
            var popups = document.querySelectorAll('.popup, .modal, .layer, .dimmed, .overlay, .toast, .banner, #popup');
            popups.forEach(function(element) { element.remove(); });
        """)
    except:
        pass

def clean_html(html_source):
    soup = BeautifulSoup(html_source, 'html.parser')
    
    for tag in soup(['script', 'style', 'meta', 'noscript', 'header', 'footer', 'iframe', 'button', 'input', 'nav', 'aside']):
        tag.decompose()

    for hidden in soup.find_all(attrs={"style": True}):
        if "display:none" in hidden["style"].replace(" ", "").lower():
            hidden.decompose()
            
    trash_ids = ['across_adn_container', 'criteo-tags-div', 'kakao-pixel-id', 'facebook-pixel-id']
    for t_id in trash_ids:
        tag = soup.find(id=t_id)
        if tag: tag.decompose()
        
    body = soup.find('body')
    return body.prettify() if body else "No Content"

def crawl_site_logic(driver, site_name, base_url, pagination_param=None, target_selector=None):
    print(f"ğŸš€ [{site_name}] ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
    collected_links = []
    last_page_links = []
    page = 1
    
    while True:
        if pagination_param:
            connector = '&' if '?' in base_url else '?'
            target_url = f"{base_url}{connector}{pagination_param}={page}"
        else:
            target_url = base_url
            
        try:
            driver.get(target_url)
            time.sleep(3)
            remove_popups(driver)
            
            if target_selector:
                try:
                    container = WebDriverWait(driver, 5).until(
                        EC.presence_of_element_located((By.CSS_SELECTOR, target_selector))
                    )
                    links = container.find_elements(By.TAG_NAME, "a")
                except:
                    links = driver.find_elements(By.TAG_NAME, "a")
            else:
                links = driver.find_elements(By.TAG_NAME, "a")

            current_page_links = []
            
            for link in links:
                try:
                    href = link.get_attribute('href')
                    if href and ('event' in href or 'view' in href or 'detail' in href or 'notice' in href) and not href.startswith('#') and 'javascript' not in href:
                        if href.startswith('/'):
                            from urllib.parse import urljoin
                            href = urljoin(base_url, href)
                        
                        if href not in current_page_links:
                            current_page_links.append(href)
                except:
                    continue
            
            if not current_page_links: break
            if sorted(current_page_links) == sorted(last_page_links): break

            for lnk in current_page_links:
                if lnk not in collected_links:
                    collected_links.append(lnk)

            if not pagination_param: break
            
            last_page_links = current_page_links
            page += 1
            if page > 10: break

        except Exception as e:
            print(f"  âš ï¸ ì˜¤ë¥˜: {e}")
            break

    print(f"  ğŸ” ìƒì„¸ ë¶„ì„ ì¤‘ ({len(collected_links)}ê±´)...")
    site_data = {}
    
    for link in collected_links:
        try:
            driver.get(link)
            time.sleep(1)
            remove_popups(driver)
            site_data[link] = clean_html(driver.page_source)
        except:
            pass
            
    return site_data

def update_index_page():
    report_files = glob.glob(os.path.join(REPORT_DIR, "report_*.html"))
    report_files.sort(reverse=True)
    
    index_html = f"""
    <!DOCTYPE html>
    <html lang="ko">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>ê²½ìŸì‚¬ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ</title>
        <style>
            body {{ font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; background-color: #f9f9f9; }}
            h1 {{ color: #333; border-bottom: 2px solid #0056b3; padding-bottom: 10px; }}
            .card {{ background: white; padding: 15px; margin-bottom: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); display: flex; justify-content: space-between; align-items: center; }}
            .card a {{ text-decoration: none; color: #0056b3; font-weight: bold; font-size: 1.1em; }}
            .card a:hover {{ text-decoration: underline; }}
            .date {{ color: #666; font-size: 0.9em; }}
            .badge {{ background-color: #28a745; color: white; padding: 3px 8px; border-radius: 12px; font-size: 0.8em; }}
        </style>
    </head>
    <body>
        <h1>ğŸ“Š ê²½ìŸì‚¬ í”„ë¡œëª¨ì…˜ ëª¨ë‹ˆí„°ë§ ì´ë ¥</h1>
        <p>ìµœì¢… ì—…ë°ì´íŠ¸: {TODAY_STR} {TIME_STR}</p>
        <div class="list-container">
    """
    
    if not report_files:
        index_html += "<p>ì•„ì§ ìƒì„±ëœ ë¦¬í¬íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.</p>"
    
    for file_path in report_files:
        filename = os.path.basename(file_path)
        date_str = filename.replace("report_", "").replace(".html", "")
        
        badge = '<span class="badge">NEW</span>' if date_str == TODAY_STR else ''
        
        index_html += f"""
            <div class="card">
                <div>
                    <a href="reports/{filename}">ğŸ“„ {date_str} ë¦¬í¬íŠ¸</a>
                    {badge}
                </div>
                <span class="date">{date_str}</span>
            </div>
        """
        
    index_html += """
        </div>
    </body>
    </html>
    """
    
    with open(os.path.join(DOCS_DIR, "index.html"), "w", encoding="utf-8") as f:
        f.write(index_html)
    print("âœ… [ëŒ€ì‹œë³´ë“œ] index.html ì—…ë°ì´íŠ¸ ì™„ë£Œ")

def main():
    driver = setup_driver()
    
    competitors = [
        {"name": "SKT ë‹¤ì´ë ‰íŠ¸", "url": "https://shop.tworld.co.kr/exhibition/submain", "param": None, "selector": "#wrap > div.container > div > div.event-list-wrap > div > ul"},
        {"name": "KTM ëª¨ë°”ì¼", "url": "https://www.ktmmobile.com/event/eventBoardList.do", "param": None, "selector": "#listArea1"},
        {"name": "U+ ìœ ëª¨ë°”ì¼", "url": "https://www.uplusumobile.com/event-benefit/event/ongoing", "param": None, "selector": "#wrap > main > div > section"},
        {"name": "í—¬ë¡œëª¨ë°”ì¼", "url": "https://direct.lghellovision.net/event/viewEventList.do?returnTab=allli&category=USIM", "param": "pageIndex", "selector": "#contentWrap > div.event-list-wrap > section > div.list-wrap > ul"},
        {"name": "ìŠ¤ì¹´ì´ë¼ì´í”„", "url": "https://www.skylife.co.kr/event?category=mobile", "param": "page", "selector": "body > div.pb-50.min-w-\[1248px\] > div.m-auto.max-w-\[1248px\].pt-20 > div > div > div.pt-14 > div > div.grid.grid-cols-3.gap-6.pt-4"}
    ]
    
    today_results = {}
    for comp in competitors:
        try:
            today_results[comp['name']] = crawl_site_logic(driver, comp['name'], comp['url'], comp['param'], comp['selector'])
        except Exception as e:
            print(f"âŒ {comp['name']} ì‹¤íŒ¨: {e}")
    
    driver.quit()
    
    latest_file = os.path.join(DATA_DIR, "latest_data.json")
    yesterday_results = {}
    if os.path.exists(latest_file):
        with open(latest_file, "r", encoding="utf-8") as f:
            yesterday_results = json.load(f)
            
    report_body = ""
    total_change_count = 0
    company_summary = []
    
    for name, pages in today_results.items():
        site_changes = ""
        site_change_count = 0 
        old_pages = yesterday_results.get(name, {})
        all_urls = set(pages.keys()) | set(old_pages.keys())
        
        for url in all_urls:
            is_changed = False
            change_html = ""
            if url in pages and url not in old_pages:
                is_changed = True
                change_html = f"<h3 style='color:green'>[NEW] <a href='{url}' target='_blank'>ìƒˆ ì´ë²¤íŠ¸</a></h3><br>"
            elif url not in pages and url in old_pages:
                is_changed = True
                change_html = f"<h3 style='color:red'>[DELETED] <a href='{url}' target='_blank'>ì¢…ë£Œë¨</a></h3><br>"
            elif pages[url].replace(" ","") != old_pages[url].replace(" ",""):
                is_changed = True
                diff = difflib.HtmlDiff().make_table(old_pages[url].splitlines(), pages[url].splitlines(), context=True, numlines=3)
                change_html = f"<h3 style='color:orange'>[UPDATED] <a href='{url}' target='_blank'>ë‚´ìš© ë³€ê²½</a></h3>{diff}<br>"
            
            if is_changed:
                site_changes += change_html
                site_change_count += 1
        
        if site_changes:
            report_body += f"<h2>{name} ({site_change_count}ê±´)</h2>{site_changes}<hr>"
            total_change_count += site_change_count
            company_summary.append(f"{name}({site_change_count})")

    summary_text = f"ì´ {total_change_count}ê±´ ì—…ë°ì´íŠ¸ ({', '.join(company_summary)})" if total_change_count > 0 else "íŠ¹ì´ì‚¬í•­ ì—†ìŒ"
    
    # [ìˆ˜ì •ë¨] ë¦¬í¬íŠ¸ ì œëª©ì— ì •í™•í•œ ìƒì„± ì‹œê°„(ì‹œ:ë¶„:ì´ˆ) í¬í•¨
    report_header = f"""
    <h1>ğŸ“… {TODAY_STR} ë¦¬í¬íŠ¸ <span style="font-size:0.6em; color:#888;">({TIME_STR} ê¸°ì¤€)</span></h1>
    <div style='background-color:#f4f4f4; padding:15px; border-radius:10px; border:1px solid #ddd;'>
        <h3>ğŸ“Š {summary_text}</h3>
        <p><a href="../index.html">ğŸ”™ ì „ì²´ ì´ë ¥ ëª©ë¡ìœ¼ë¡œ ëŒì•„ê°€ê¸°</a></p>
    </div>
    <hr>
    """
    full_report = report_header + (report_body if total_change_count > 0 else "<p>âœ… ê¸ˆì¼ ë³€ë™ ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.</p>")
    
    filename = f"report_{TODAY_STR}.html"
    with open(os.path.join(REPORT_DIR, filename), "w", encoding="utf-8") as f:
        f.write(full_report)
        
    with open(latest_file, "w", encoding="utf-8") as f:
        json.dump(today_results, f, ensure_ascii=False)

    update_index_page()

    dashboard_url = f"https://{GITHUB_USER}.github.io/{REPO_NAME}/"
    report_url = f"https://{GITHUB_USER}.github.io/{REPO_NAME}/reports/{filename}"
    
    if total_change_count > 0:
        payload = {
            "text": f"ğŸ“¢ *[{TODAY_STR} {TIME_STR}] ê²½ìŸì‚¬ ë™í–¥ ë³´ê³ * \n\nâœ… *ìš”ì•½:* {summary_text}\nğŸ‘‰ *ì˜¤ëŠ˜ ë¦¬í¬íŠ¸:* {report_url}\nğŸ“‚ *ì „ì²´ ì´ë ¥:* {dashboard_url}"
        }
    else:
        payload = {
            "text": f"ğŸ“‹ *[{TODAY_STR} {TIME_STR}] ê²½ìŸì‚¬ ë™í–¥ ë³´ê³ * \n\nâœ… íŠ¹ì´ì‚¬í•­ ì—†ìŒ\nğŸ“‚ *ì „ì²´ ì´ë ¥:* {dashboard_url}"
        }
        
    if SLACK_WEBHOOK_URL:
        requests.post(SLACK_WEBHOOK_URL, json=payload)
        print("âœ… ìŠ¬ë™ ì•Œë¦¼ ì™„ë£Œ")
    else:
        print("âš ï¸ ìŠ¬ë™ URL ì—†ìŒ")

if __name__ == "__main__":
    main()
